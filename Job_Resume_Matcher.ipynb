{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagrit-goyal/Job-Resume-Matcher/blob/main/Job_Resume_Matcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiUYD1fpyAgF",
        "outputId": "54dd31e9-2f90-4fdd-ca36-d2eb82406646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.5\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0c287bb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51dddac2-9009-4191-bb5f-776dd0cfafd5"
      },
      "source": [
        "import pymupdf  # PyMuPDF for PDF\n",
        "import docx2txt  # for DOCX\n",
        "import os\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    \"\"\"Extract text from PDF using PyMuPDF\"\"\"\n",
        "    text = \"\"\n",
        "    pdf_doc = pymupdf.open(file_path)\n",
        "    for page in pdf_doc:\n",
        "        text += page.get_text(\"text\")\n",
        "    pdf_doc.close()\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    \"\"\"Extract text from DOCX using docx2txt\"\"\"\n",
        "    return docx2txt.process(file_path)\n",
        "\n",
        "def extract_resume_text(file_path):\n",
        "    \"\"\"Auto-detect file type and extract text\"\"\"\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif ext == \".docx\":\n",
        "        return extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    resume_file = \"/content/Resume.pdf\"\n",
        "    text = extract_resume_text(resume_file)\n",
        "    print(\"Extracted Resume Text:\\n\")\n",
        "    print(text[:1000])  # print first 1000 chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Resume Text:\n",
            "\n",
            " \n",
            "Jagrit Goyal \n",
            "jagritgoyal31@gmail.com | LinkedIn: jagrit31 | GitHub: jagrit-goyal | +91-7814768600 \n",
            "EDUCATION​\n",
            "​\n",
            "​\n",
            "​ \n",
            "Thapar University​\n",
            "                                                   ​\n",
            "Patiala, Punjab \n",
            "B.Tech in Computer Science and Engineering​\n",
            "​\n",
            "  Expected Graduation, May 2026 \n",
            "CGPA: 8.43 (Till Now) \n",
            " \n",
            "WORK EXPERIENCE​\n",
            "​\n",
            "​\n",
            " \n",
            "ELC | Summer Intern−PCB Component Detection and Layout Automation: Jun 2025 - July 2025 \n",
            "●​\n",
            "Developed a YOLO-based deep learning model for PCB component detection, achieving over 93% accuracy on \n",
            "high-complexity circuit board images. \n",
            "●​\n",
            "Implemented OCR techniques to automatically extract component labels from PCB layouts, enabling automated data \n",
            "extraction for 92% of cases. \n",
            "●​ Streamlined the PCB layout generation process by integrating object detection and OCR into a unified pipeline, \n",
            "resulting in a 45% reduction in processing time. \n",
            "PROJECTS ​ ​\n",
            "​\n",
            "​\n",
            " \n",
            "ELC Connect – Smart Room Booking & Attendance System \n",
            "Tools: Next Js, Mongo DB, REST APIs, JWT Authe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I4XjqIgBG89v",
        "outputId": "d29d6ce1-beb1-4ced-eee4-87dcd2ad65df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# skill_extractor.py\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example skill dictionary (you can expand this from Kaggle skill lists)\n",
        "SKILLS = [\n",
        "    \"python\", \"java\", \"c++\", \"sql\", \"html\", \"css\", \"javascript\", \"react\",\n",
        "    \"node.js\", \"machine learning\", \"deep learning\", \"nlp\", \"pandas\", \"numpy\",\n",
        "    \"tensorflow\", \"pytorch\", \"data analysis\", \"docker\", \"aws\", \"git\"\n",
        "]\n",
        "\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extract entities like education, organizations, names, dates\"\"\"\n",
        "    doc = nlp(text)\n",
        "    entities = {\"ORG\": [], \"PERSON\": [], \"DATE\": [], \"GPE\": []}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entities:\n",
        "            entities[ent.label_].append(ent.text)\n",
        "    return entities\n",
        "\n",
        "def extract_skills(text):\n",
        "    \"\"\"Extract skills by simple dictionary matching\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    found_skills = []\n",
        "    for skill in SKILLS:\n",
        "        # use regex for whole-word matching\n",
        "        if re.search(r\"\\b\" + re.escape(skill.lower()) + r\"\\b\", text_lower):\n",
        "            found_skills.append(skill)\n",
        "    return list(set(found_skills))  # remove duplicates\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract skills & entities\n",
        "    skills = extract_skills(text)\n",
        "    entities = extract_entities(text)\n",
        "\n",
        "    print(\"Extracted Skills:\", skills)\n",
        "    print(\"Extracted Entities:\", entities)\n"
      ],
      "metadata": {
        "id": "8_r5vFFKG9qI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dca53dd-f9b8-4af3-afac-4f186c5575bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Skills: ['git', 'html', 'sql', 'node.js', 'pandas', 'python', 'deep learning', 'javascript', 'css', 'numpy', 'data analysis']\n",
            "Extracted Entities: {'ORG': ['GitHub', 'Computer Science', 'Summer Intern−PCB Component Detection', 'YOLO', 'PCB', 'PCB', 'PCB', 'OCR', 'JWT Authentication', 'API', 'CSS', 'JavaScript', 'Thapar University', 'Software Engineering', 'TCS', 'HTML/CSS', 'JavaScript', 'SQL', 'Data Analytics Essentials'], 'PERSON': ['Thapar', 'Patiala', 'Mongo DB', 'mark attendance', 'Express Js', 'C++', 'Express JS', 'Pandas', 'Matplotlib', 'Sklearn', 'Jupyter Notebook', 'JEE'], 'DATE': ['May 2026', '2025 - July 2025', '150+ weekly', '8+', '300+', 'August 2024', '5+'], 'GPE': ['Node.js', 'Express.js', 'Numpy', 'Cisco']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "nBn9A9QHpdE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load BERT model (MiniLM is lightweight & fast)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def bert_resume_match(text, job_description):\n",
        "    # Create embeddings\n",
        "    embeddings = model.encode([text, job_description], convert_to_tensor=True)\n",
        "\n",
        "    # Cosine similarity\n",
        "    similarity = util.cos_sim(embeddings[0], embeddings[1])\n",
        "    return float(similarity)\n",
        "\n",
        "# Example Job Description\n",
        "job_description = \"\"\"\n",
        "Responsibilities:\n",
        "\n",
        "● Design, develop, and maintain full-stack web applications using the MERN stack (MongoDB, Express.js, React, Node.js)\n",
        "● Build responsive, intuitive, and high-performance front-end interfaces\n",
        "● Develop and optimize backend APIs and microservices for scalability and reliability\n",
        "● Collaborate with design, AI, and backend teams to integrate intelligent and interactive features\n",
        "● Ensure clean, maintainable, and well-documented code with strong testing coverage\n",
        "\n",
        "Preferred Skills:\n",
        "\n",
        "● Strong proficiency in JavaScript, React.js, Node.js, Express.js, and MongoDB\n",
        "● Experience with RESTful APIs, GraphQL, and WebSockets\n",
        "● Familiarity with modern front-end tooling (Webpack, Babel, Vite)\n",
        "● Understanding of cloud deployment (AWS, GCP, or Azure) and CI/CD pipelines\n",
        "● Knowledge of TypeScript, Redis, and Docker is a plus\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Resume text = your extracted text\n",
        "score = bert_resume_match(text, job_description)\n",
        "print(f\"BERT Resume–Job Match Score: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4iRReWVpETt",
        "outputId": "76349f25-e9c8-4e47-f47e-ead687d7bcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Resume–Job Match Score: 0.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6FKUGYR4V6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}